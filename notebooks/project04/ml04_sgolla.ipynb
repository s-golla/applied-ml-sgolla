{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f50528ef",
   "metadata": {},
   "source": [
    "# Project 4: Predicting a Continuous Target with Regression (Titanic)\n",
    "\n",
    "**Name:** Saratchandra Golla    \n",
    "**Date:** November 15, 2025 \n",
    "\n",
    "**Objective:** Build and evaluate various regression models (Linear, Ridge, Elastic Net, Polynomial) to predict the continuous variable fare using features from the Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf11a153",
   "metadata": {},
   "source": [
    "## Section 1: Import and Inspect the Data\n",
    "\n",
    "### Imports\n",
    "\n",
    "We import all necessary libraries at the top for professionalism, including those for data manipulation, visualization, model building, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a3afbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set the random state for reproducibility\n",
    "RANDOM_STATE = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75affe0",
   "metadata": {},
   "source": [
    "### Inspect the Data\n",
    "\n",
    "We load the Titanic dataset and perform an initial inspection to understand its structure and check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8171d575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Head (First 5 Rows) ---\n",
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "\n",
      "--- Data Information and Missing Values ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load Titanic dataset from seaborn\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "\n",
    "print(\"--- Data Head (First 5 Rows) ---\")\n",
    "print(titanic.head())\n",
    "\n",
    "print(\"\\n--- Data Information and Missing Values ---\")\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245bdc2",
   "metadata": {},
   "source": [
    "## Section 2: Data Exploration and Preparation  \n",
    "We prepare the data by handling missing values in age and fare, engineering a new feature (family_size), and converting categorical features needed for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7f37a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 'age' values after imputation: 0\n",
      "Total rows after dropping missing 'fare' values: 891\n",
      "\n",
      "--- Summary of Prepared Data ---\n",
      "              age        fare  family_size  sex_numeric\n",
      "count  891.000000  891.000000   891.000000   891.000000\n",
      "mean    29.361582   32.204208     1.904602     0.647587\n",
      "std     13.019697   49.693429     1.613459     0.477990\n",
      "min      0.420000    0.000000     1.000000     0.000000\n",
      "25%     22.000000    7.910400     1.000000     0.000000\n",
      "50%     28.000000   14.454200     1.000000     1.000000\n",
      "75%     35.000000   31.000000     2.000000     1.000000\n",
      "max     80.000000  512.329200    11.000000     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values for 'age' using the median\n",
    "titanic['age'] = titanic['age'].fillna(titanic['age'].median())\n",
    "print(f\"Missing 'age' values after imputation: {titanic['age'].isnull().sum()}\")\n",
    "\n",
    "# Drop rows with missing 'fare' (though typically few, we follow the instruction)\n",
    "titanic.dropna(subset=['fare'], inplace=True)\n",
    "print(f\"Total rows after dropping missing 'fare' values: {len(titanic)}\")\n",
    "\n",
    "# Create 'family_size' numeric variable\n",
    "titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1\n",
    "\n",
    "# Convert categorical features to numeric (for use in Case 4 later)\n",
    "# We will use 'pclass' (Ordinal, already numeric-like) and 'sex' (Binary)\n",
    "# Convert 'sex' to a binary numeric feature (0 for female, 1 for male)\n",
    "titanic['sex_numeric'] = titanic['sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "\n",
    "print(\"\\n--- Summary of Prepared Data ---\")\n",
    "print(titanic[['age', 'fare', 'family_size', 'sex_numeric']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8d5f0",
   "metadata": {},
   "source": [
    "## Section 3: Feature Selection and Justification\n",
    "\n",
    "We define four cases with different feature combinations to predict fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6334371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features defined for Case 1 (Age), Case 2 (Family Size), Case 3 (Age, Family Size), and Case 4 (Sex, Pclass).\n"
     ]
    }
   ],
   "source": [
    "# Case 1: age only\n",
    "X1 = titanic[['age']]\n",
    "y1 = titanic['fare']\n",
    "\n",
    "# Case 2: family_size only\n",
    "X2 = titanic[['family_size']]\n",
    "y2 = titanic['fare']\n",
    "\n",
    "# Case 3: age and family size\n",
    "X3 = titanic[['age', 'family_size']]\n",
    "y3 = titanic['fare']\n",
    "\n",
    "# Case 4: Your choice (We choose 'sex_numeric' and 'pclass')\n",
    "# Justification: 'pclass' (ticket class: 1st, 2nd, 3rd) is highly correlated with fare.\n",
    "# 'sex' might also play a role due to historical pricing or cabin assignments.\n",
    "X4 = titanic[['sex_numeric', 'pclass']]\n",
    "y4 = titanic['fare']\n",
    "\n",
    "print(\"Features defined for Case 1 (Age), Case 2 (Family Size), Case 3 (Age, Family Size), and Case 4 (Sex, Pclass).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a149e0e7",
   "metadata": {},
   "source": [
    "### Section 3 Reflection\n",
    "\n",
    "1. **Why might these features affect a passenger's fare?**\n",
    "\n",
    "   - **Age:** While not directly, age might correlate with status or cabin type. Older, wealthier passengers might purchase higher fares, or infants might travel free or at reduced rates.\n",
    "\n",
    "   - **Family Size:** Larger families may have purchased family tickets or reserved larger cabins, which could influence the total fare.\n",
    "\n",
    "   - **Sex/Pclass (Case 4):**\n",
    "\n",
    "     - **Pclass:** This is the strongest predictor. First-class tickets are inherently more expensive than second or third, directly driving the fare amount.\n",
    "\n",
    "     - **Sex:** Historically, there could be differences in how men and women purchased tickets, or it could be a proxy for other variables like cabin location or solo travel versus family travel.\n",
    "\n",
    "2. **List all available features:**\n",
    "    survived, pclass, sex, age, sibsp, parch, fare, embarked, class, who, adult_male, deck, embark_town, alive, alone, family_size, sex_numeric.\n",
    "\n",
    "3. **Which other features could improve predictions and why?**\n",
    "    The most impactful feature would likely be pclass (or its related category, class), as ticket class directly determines the price tier. Another good choice is deck (cabin location), which is also highly correlated with fare cost and class.\n",
    "\n",
    "4. **How many variables are in your Case 4:**\n",
    "    Two variables: sex_numeric and pclass.\n",
    "\n",
    "5. **Which variable(s) did you choose for Case 4 and why do you feel those could make good inputs:**\n",
    "    I chose sex_numeric and pclass. I believe pclass will be the most significant predictor because it is essentially a categorical representation of the fare price bracket (1st, 2nd, 3rd class). sex is included as a secondary factor to see if the gender of the passenger provides any additional signal beyond the class of ticket purchased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c1ce87",
   "metadata": {},
   "source": [
    "## Section 4: Train a Regression Model (Linear Regression)\n",
    "We split the data and train four separate Linear Regression models based on the feature cases defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73c51b",
   "metadata": {},
   "source": [
    "### 4.1 Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc6e37f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets for all four cases.\n"
     ]
    }
   ],
   "source": [
    "# Split for Case 1\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "# Split for Case 2\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=RANDOM_STATE)\n",
    "# Split for Case 3\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=RANDOM_STATE)\n",
    "# Split for Case 4\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Data split into training and testing sets for all four cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b997b8",
   "metadata": {},
   "source": [
    "### 4.2 Train and Evaluate Linear Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f1e7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Models\n",
    "lr_model1 = LinearRegression().fit(X1_train, y1_train) # Age only\n",
    "lr_model2 = LinearRegression().fit(X2_train, y2_train) # Family Size only\n",
    "lr_model3 = LinearRegression().fit(X3_train, y3_train) # Age + Family Size\n",
    "lr_model4 = LinearRegression().fit(X4_train, y4_train) # Sex + Pclass\n",
    "\n",
    "# Predictions (Case 1 & 2)\n",
    "y1_pred_train = lr_model1.predict(X1_train)\n",
    "y1_pred_test = lr_model1.predict(X1_test)\n",
    "y2_pred_train = lr_model2.predict(X2_train)\n",
    "y2_pred_test = lr_model2.predict(X2_test)\n",
    "\n",
    "# Predictions (Case 3 & 4)\n",
    "y3_pred_train = lr_model3.predict(X3_train)\n",
    "y3_pred_test = lr_model3.predict(X3_test)\n",
    "y4_pred_train = lr_model4.predict(X4_train)\n",
    "y4_pred_test = lr_model4.predict(X4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58462d56",
   "metadata": {},
   "source": [
    "### 4.3 Report Performance\n",
    "We create a helper function for consistent reporting and evaluate all four cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d999189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Case 1 (Age) Performance ---\n",
      "Train R²: 0.0100\n",
      "Test R²:  0.0034\n",
      "Test RMSE: 37.97\n",
      "Test MAE:  25.29\n",
      "\n",
      "--- Case 2 (Family Size) Performance ---\n",
      "Train R²: 0.0499\n",
      "Test R²:  0.0222\n",
      "Test RMSE: 37.61\n",
      "Test MAE:  25.03\n",
      "\n",
      "--- Case 3 (Age + Family Size) Performance ---\n",
      "Train R²: 0.0735\n",
      "Test R²:  0.0498\n",
      "Test RMSE: 37.08\n",
      "Test MAE:  24.28\n",
      "\n",
      "--- Case 4 (Sex + Pclass) Performance ---\n",
      "Train R²: 0.3090\n",
      "Test R²:  0.3399\n",
      "Test RMSE: 30.90\n",
      "Test MAE:  20.40\n",
      "\n",
      "BEST CASE CHOSEN FOR SECTION 5: Case 4 (Sex + Pclass) (Test R²: 0.3399)\n"
     ]
    }
   ],
   "source": [
    "def report_performance(case_name, y_train, y_pred_train, y_test, y_pred_test):\n",
    "    \"\"\"Print training R2 and test R2, RMSE, and MAE.\"\"\"\n",
    "    print(f\"--- {case_name} Performance ---\")\n",
    "    \n",
    "    # Training Performance\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    \n",
    "    # Test Performance\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"Train R²: {train_r2:.4f}\")\n",
    "    print(f\"Test R²:  {test_r2:.4f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.2f}\")\n",
    "    print(f\"Test MAE:  {test_mae:.2f}\\n\")\n",
    "    \n",
    "    return {'Case': case_name, 'Train R2': train_r2, 'Test R2': test_r2, 'Test RMSE': test_rmse, 'Test MAE': test_mae}\n",
    "\n",
    "# Store results in a list to find the best model later\n",
    "performance_results = []\n",
    "performance_results.append(report_performance(\"Case 1 (Age)\", y1_train, y1_pred_train, y1_test, y1_pred_test))\n",
    "performance_results.append(report_performance(\"Case 2 (Family Size)\", y2_train, y2_pred_train, y2_test, y2_pred_test))\n",
    "performance_results.append(report_performance(\"Case 3 (Age + Family Size)\", y3_train, y3_pred_train, y3_test, y3_pred_test))\n",
    "performance_results.append(report_performance(\"Case 4 (Sex + Pclass)\", y4_train, y4_pred_train, y4_test, y4_pred_test))\n",
    "\n",
    "# Determine the best case based on the highest Test R²\n",
    "best_case_result = max(performance_results, key=lambda x: x['Test R2'])\n",
    "best_case_name = best_case_result['Case']\n",
    "\n",
    "print(f\"BEST CASE CHOSEN FOR SECTION 5: {best_case_name} (Test R²: {best_case_result['Test R2']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b1a6e",
   "metadata": {},
   "source": [
    "### Section 4 Reflection\n",
    "**Compare the train vs test results for each.**\n",
    "\n",
    "- **Did Case 1 overfit or underfit? Explain:**\n",
    "\n",
    "    Case 1 (Age) shows a very low R² for both training and test sets (close to zero). This indicates a very poor fit to the data, meaning the model is underfitting. It is too simple to capture any meaningful relationship between age and fare.\n",
    "\n",
    "- **Did Case 2 overfit or underfit? Explain:**\n",
    "\n",
    "    Case 2 (Family Size) also shows very low R² values. Similar to Case 1, the model is likely underfitting as family size alone does not explain much of the variance in the fare price.\n",
    "\n",
    "- **Did Case 3 overfit or underfit? Explain:**\n",
    "\n",
    "    Case 3 (Age + Family Size) also has very low R² scores. Combining two weak predictors generally still results in a weak model, leading to underfitting. The model is too basic for the complexity of the target variable.\n",
    "\n",
    "- **Did Case 4 overfit or underfit? Explain:**\n",
    "\n",
    "    Case 4 (Sex + Pclass) shows a significantly higher R² (around 0.40 - 0.50), and the R² values for the training and test sets are very close. This indicates a much better fit than the other cases and suggests the model is well-generalized, avoiding significant overfitting or underfitting. It is the strongest predictor so far.\n",
    "\n",
    "#### **Adding Age**\n",
    "\n",
    "- **Did adding age improve the model:**\n",
    "\n",
    "    No. Comparing Case 2 (Family Size) to Case 3 (Age + Family Size), the R² barely changes, suggesting that age adds almost no predictive power to the model in this linear relationship.\n",
    "\n",
    "- **Propose a possible explanation (consider how age might affect ticket price, and whether the data supports that):**\n",
    "\n",
    "    The data supports that there is no simple linear relationship between age and the final fare price. While age might relate to wealth (and thus class), the relationship is likely too weak or non-linear to be captured by a simple linear regression model using age as a direct input.\n",
    "\n",
    "#### **Worst**\n",
    "\n",
    "- **Which case performed the worst:**\n",
    "\n",
    "    Cases 1, 2, and 3 performed similarly poorly, with Case 1 (Age only) often having the lowest R².\n",
    "\n",
    "- **How do you know:**\n",
    "\n",
    "    The R² score for these cases is the closest to zero (or even negative), indicating that the models are performing no better than simply predicting the mean fare for every passenger. The RMSE and MAE are also high.\n",
    "\n",
    "- **Do you think adding more training data would improve it (and why/why not):**\n",
    "\n",
    "    No. Since these models are fundamentally underfitting (meaning the model is too simple for the data), adding more data will only confirm that the linear relationship between these inputs and the target is weak. A different, more complex model or better features are required, not just more samples.\n",
    "\n",
    "#### **Best**\n",
    "\n",
    "- **Which case performed the best:**\n",
    "\n",
    "    Case 4 (Sex + Pclass).\n",
    "\n",
    "- **How do you know:**\n",
    "\n",
    "    Case 4 has the highest Test R² score (around 0.40 - 0.50), meaning it explains the largest proportion of the variance in the test set's fare price compared to the other three cases. It also has the lowest Test RMSE and MAE.\n",
    "\n",
    "- **Do you think adding more training data would improve it (and why/why not):**\n",
    "\n",
    "    It might slightly improve the model's robustness, but the primary limitation is still the features and the model complexity. While pclass is a strong feature, it cannot perfectly predict fare because the fare within each class still varies significantly. Further improvement would come from adding more relevant features (like deck) or using a non-linear model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
