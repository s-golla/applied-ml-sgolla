{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36044430",
   "metadata": {},
   "source": [
    "# Project 5: Ensemble Models on Wine Quality\n",
    "\n",
    "**Name:** Saratchandra Golla    \n",
    "**Date:** November 15, 2025\n",
    "\n",
    "**Introduction:**   \n",
    "This project explores the use of ensemble machine learning models to classify the quality of red wine using physicochemical properties from the UCI Wine Quality Dataset. Ensemble methods, which combine multiple models, are powerful tools for improving predictive performance by reducing overfitting and enhancing generalization . The goal is to compare the performance of selected ensemble models and determine the best approach for this multi-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adba7da",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We import all necessary libraries for data loading, preprocessing, model building (including ensemble methods), cross-validation, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd36785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensemble Models\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "# Base Estimators for Voting and Bagging\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Utilities and Metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028eb2a",
   "metadata": {},
   "source": [
    "## Section 1. Load and Inspect the Data\n",
    "We load the Red Wine Quality Dataset. The original dataset contains 11 physicochemical features and a quality target variable . We use a semicolon (;) as a separator for the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f205589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Wine Quality Dataset Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "\n",
      "--- Wine Quality Dataset Head ---\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n",
      "\n",
      "Dataset loaded with 1599 samples and 12 columns (11 features + quality).\n"
     ]
    }
   ],
   "source": [
    "# Load the wine quality dataset\n",
    "try:\n",
    "    df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'winequality-red.csv' not found. Please ensure the file is in the same directory.\")\n",
    "    df = None # Handle case where file is missing\n",
    "\n",
    "if df is not None:\n",
    "    print(\"--- Wine Quality Dataset Info ---\")\n",
    "    df.info()\n",
    "    print(\"\\n--- Wine Quality Dataset Head ---\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nDataset loaded with {len(df)} samples and 12 columns (11 features + quality).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1372ef3",
   "metadata": {},
   "source": [
    "## Section 2. Prepare the Data\n",
    "The original quality target variable is an integer score from 0 to 10. For a more practical classification task, we simplify this into three categorical levels: low (quality $\\le 4$), medium (quality $\\le 6$), and high (quality $\\ge 7$) \n",
    "\n",
    "We create two new columns:\n",
    "1. **quality_label:** a categorical string (low, medium, high)\n",
    "2. **quality_numeric:** a numeric encoding of the label ($0=$ low, $1=$ medium, $2=$ high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75f6cfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Preparation Complete ---\n",
      "   quality quality_label  quality_numeric\n",
      "0        5        medium                1\n",
      "1        5        medium                1\n",
      "2        5        medium                1\n",
      "3        6        medium                1\n",
      "4        5        medium                1\n",
      "\n",
      "Distribution of the new target variable:\n",
      "quality_label\n",
      "medium    1319\n",
      "high       217\n",
      "low         63\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # 1. Helper function to map quality score to a string label\n",
    "    def quality_to_label(q):\n",
    "        \"\"\"Return the quality label (low, medium, high) based on the quality score q.\"\"\"\n",
    "        if q <= 4:\n",
    "            return \"low\"\n",
    "        elif q <= 6:\n",
    "            return \"medium\"\n",
    "        else: # q >= 7\n",
    "            return \"high\"\n",
    "    \n",
    "    # Apply the function to create the new label column\n",
    "    df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)\n",
    "\n",
    "    # 2. Helper function to map quality score to a numeric target\n",
    "    def quality_to_number(q):\n",
    "        \"\"\"Return the numeric quality target (0=low, 1=medium, 2=high).\"\"\"\n",
    "        if q <= 4:\n",
    "            return 0\n",
    "        elif q <= 6:\n",
    "            return 1\n",
    "        else: # q >= 7\n",
    "            return 2\n",
    "            \n",
    "    # Apply the function to create the numeric target column\n",
    "    df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)\n",
    "    \n",
    "    print(\"\\n--- Data Preparation Complete ---\")\n",
    "    print(df[['quality', 'quality_label', 'quality_numeric']].head())\n",
    "    print(\"\\nDistribution of the new target variable:\")\n",
    "    print(df['quality_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd31f7c",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification\n",
    "We define the feature set (X) to include all physicochemical columns and the target variable (y) as the newly created quality_numeric column . We justify excluding the original quality and the new categorical columns (quality_label and quality_numeric) from the input features, as they are either the target itself or a direct transformation of the target, and would cause data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87d95fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature and Target Shape ---\n",
      "Features (x) shape: (1599, 11)\n",
      "Target (y) shape: (1599,)\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # Features (x): all physicochemical columns\n",
    "    x = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])\n",
    "\n",
    "    # Target (y): the new numeric quality category\n",
    "    y = df[\"quality_numeric\"]\n",
    "\n",
    "    print(\"\\n--- Feature and Target Shape ---\")\n",
    "    print(f\"Features (x) shape: {x.shape}\")\n",
    "    print(f\"Target (y) shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeddf08",
   "metadata": {},
   "source": [
    "## Section 4. Split the Data into Train and Test\n",
    "The data is split into 80% for training and 20% for testing using train_test_split. We use stratify=y to ensure that the class proportions (low, medium, high) are preserved in both the training and testing sets, which is important for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d48c79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Split Complete ---\n",
      "x_train shape: (1279, 11)\n",
      "x_test shape: (320, 11)\n",
      "y_train class distribution:\n",
      "quality_numeric\n",
      "1    0.824863\n",
      "2    0.136044\n",
      "0    0.039093\n",
      "Name: proportion, dtype: float64\n",
      "y_test class distribution:\n",
      "quality_numeric\n",
      "1    0.825000\n",
      "2    0.134375\n",
      "0    0.040625\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(\"\\n--- Data Split Complete ---\")\n",
    "    print(f\"x_train shape: {x_train.shape}\")\n",
    "    print(f\"x_test shape: {x_test.shape}\")\n",
    "    print(f\"y_train class distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "    print(f\"y_test class distribution:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0bd5bb",
   "metadata": {},
   "source": [
    "## Section 5. Evaluate Model Performance\n",
    "We define a helper function evaluate_model to streamline the training, prediction, and metric calculation process for consistency across models. We will focus on Train Accuracy, Test Accuracy, Train F1 Score, and Test F1 Score (weighted average) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fecc89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to train and evaluate models\n",
    "def evaluate_model(name, model, x_train, y_train, x_test, y_test, results):\n",
    "    \"\"\"Trains a model, calculates performance metrics, and appends to results list.\"\"\"\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train)\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    # Append to results list\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train F1\": train_f1,\n",
    "            \"Test F1\": test_f1\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Initialize results list\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f52adc",
   "metadata": {},
   "source": [
    "### Section 5.1 - Model 1: Random Forest (100)\n",
    "A strong, parallel ensemble of 100 decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "278f819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model 1: Random Forest (100) ---\n",
      "\n",
      "Random Forest (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 256   8]\n",
      " [  0  15  28]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8875\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8661\n"
     ]
    }
   ],
   "source": [
    "# 1. Random Forest (100)\n",
    "print(\"\\n--- Evaluating Model 1: Random Forest (100) ---\")\n",
    "if df is not None:\n",
    "    evaluate_model(\n",
    "        \"Random Forest (100)\",\n",
    "        RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        results,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
